{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', download =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    " image,label = dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image,cmap='gray')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',train= True,transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, label = dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 3\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split(n,val_pct):\n",
    "    \n",
    "    n_val = int(val_pct *n)\n",
    "    \n",
    "    indxs = np.random.permutation(n)\n",
    "    \n",
    "    return indxs[n_val:], indxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indics , val_indics = split(len(dataset),val_pct = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_indics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indics)\n",
    "train_loader = DataLoader(dataset, batch_size, sampler = train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_indics)\n",
    "val_loader = DataLoader(dataset, batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_class = 10\n",
    "\n",
    "model = nn.Linear(input_size,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0061, -0.0192, -0.0043,  ...,  0.0005,  0.0139, -0.0310],\n",
       "        [-0.0059, -0.0036,  0.0129,  ...,  0.0087,  0.0096,  0.0210],\n",
       "        [ 0.0262, -0.0306,  0.0038,  ..., -0.0305,  0.0300,  0.0079],\n",
       "        ...,\n",
       "        [ 0.0246,  0.0084, -0.0290,  ...,  0.0038,  0.0221, -0.0356],\n",
       "        [ 0.0037, -0.0102,  0.0176,  ...,  0.0319, -0.0306,  0.0035],\n",
       "        [ 0.0331,  0.0031,  0.0093,  ..., -0.0270,  0.0306, -0.0135]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0061, -0.0192, -0.0043,  ...,  0.0005,  0.0139, -0.0310],\n",
       "         [-0.0059, -0.0036,  0.0129,  ...,  0.0087,  0.0096,  0.0210],\n",
       "         [ 0.0262, -0.0306,  0.0038,  ..., -0.0305,  0.0300,  0.0079],\n",
       "         ...,\n",
       "         [ 0.0246,  0.0084, -0.0290,  ...,  0.0038,  0.0221, -0.0356],\n",
       "         [ 0.0037, -0.0102,  0.0176,  ...,  0.0319, -0.0306,  0.0035],\n",
       "         [ 0.0331,  0.0031,  0.0093,  ..., -0.0270,  0.0306, -0.0135]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0037, -0.0134,  0.0015,  0.0307, -0.0106,  0.0125,  0.0270, -0.0182,\n",
       "          0.0207, -0.0147], requires_grad=True)]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 9, 8, 7, 6, 8, 9, 2, 9, 9, 0, 6, 0, 3, 6, 9, 4, 7, 5, 1, 3, 9, 2, 3,\n",
      "        6, 9, 0, 3, 9, 1, 4, 7, 4, 9, 1, 3, 7, 8, 2, 2, 1, 2, 5, 8, 5, 6, 1, 3,\n",
      "        2, 4, 1, 5, 2, 7, 0, 0, 3, 5, 5, 6, 6, 7, 2, 7, 4, 8, 4, 7, 0, 5, 3, 7,\n",
      "        3, 7, 5, 0, 5, 5, 8, 1, 1, 5, 5, 8, 7, 8, 9, 6, 1, 7, 7, 5, 8, 8, 4, 6,\n",
      "        8, 2, 3, 0])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-c2d48354dab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images,labels in train_loader:\n",
    "    \n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinstModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear= nn.Linear(input_size,num_class)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        \n",
    "        xb= xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MinstModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0172e-02,  2.6524e-02, -2.2514e-02,  ..., -1.8131e-02,\n",
       "          -1.2181e-02, -3.3549e-02],\n",
       "         [ 6.4409e-03,  8.6560e-03, -2.1599e-05,  ..., -1.5993e-02,\n",
       "           2.5617e-02, -3.4892e-02],\n",
       "         [-1.0871e-02,  3.3088e-02, -2.7079e-02,  ...,  3.9537e-03,\n",
       "          -9.7031e-03,  1.8536e-03],\n",
       "         ...,\n",
       "         [-3.5478e-02,  3.0814e-02, -6.8295e-03,  ...,  7.3560e-03,\n",
       "           3.0547e-02, -3.2367e-02],\n",
       "         [-9.6961e-03, -3.2379e-02, -2.7888e-02,  ...,  4.8913e-03,\n",
       "          -3.5243e-02,  1.1283e-02],\n",
       "         [-4.1907e-03,  3.5411e-02, -1.5161e-02,  ..., -1.7619e-02,\n",
       "           6.5771e-03,  1.1695e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0153,  0.0079, -0.0116,  0.0207,  0.0323,  0.0059,  0.0169, -0.0017,\n",
       "         -0.0310,  0.0035], requires_grad=True)]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images,labels in train_loader:\n",
    "    \n",
    "    outputs = model(images)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0118, -0.0647, -0.1010, -0.0222,  0.5114,  0.3320, -0.1123,  0.0475,\n",
       "          0.1765, -0.3266],\n",
       "        [-0.3049,  0.2880,  0.0607, -0.1807,  0.3005,  0.2058,  0.1377, -0.1400,\n",
       "          0.1903, -0.1846]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Probabilities : \n",
      "  tensor([[0.0941, 0.0872, 0.0841, 0.0910, 0.1551, 0.1297, 0.0831, 0.0976, 0.1110,\n",
      "         0.0671],\n",
      "        [0.0695, 0.1258, 0.1002, 0.0787, 0.1273, 0.1158, 0.1082, 0.0820, 0.1141,\n",
      "         0.0784]])\n",
      "Sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(outputs,dim= 1)\n",
    "print('Sample Probabilities : \\n ', probs[:2].data)\n",
    "\n",
    "print('Sum:',torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1551, 0.1273, 0.1224, 0.1194, 0.1215, 0.1393, 0.1355, 0.1209, 0.1173,\n",
      "        0.1910, 0.1330, 0.1316, 0.1217, 0.1311, 0.1531, 0.1217, 0.1241, 0.1356,\n",
      "        0.1078, 0.1187, 0.1335, 0.1282, 0.1251, 0.1196, 0.1237, 0.1349, 0.1265,\n",
      "        0.1282, 0.1234, 0.1206, 0.1161, 0.1195, 0.1292, 0.1473, 0.1325, 0.1448,\n",
      "        0.1211, 0.1583, 0.1178, 0.1560, 0.1370, 0.1397, 0.1298, 0.1125, 0.1316,\n",
      "        0.1297, 0.1341, 0.1256, 0.1399, 0.1288, 0.1423, 0.1290, 0.1296, 0.1285,\n",
      "        0.1217, 0.1267, 0.1516, 0.1381, 0.1290, 0.1224, 0.1270, 0.1535, 0.1214,\n",
      "        0.1235, 0.1303, 0.1565, 0.1180, 0.1260, 0.1259, 0.1754, 0.1473, 0.1176,\n",
      "        0.1348, 0.1486, 0.1148, 0.1175, 0.1235, 0.1369, 0.1549, 0.1211, 0.1291,\n",
      "        0.1134, 0.1182, 0.1419, 0.1209, 0.1178, 0.1248, 0.1479, 0.1277, 0.1259,\n",
      "        0.1304, 0.1315, 0.1332, 0.1168, 0.1243, 0.1339, 0.1247, 0.1168, 0.1341,\n",
      "        0.1261], grad_fn=<MaxBackward0>)\n",
      "tensor([4, 4, 4, 5, 1, 0, 4, 4, 4, 4, 4, 0, 1, 1, 4, 4, 8, 0, 1, 4, 2, 1, 1, 4,\n",
      "        2, 1, 1, 4, 8, 5, 5, 8, 4, 4, 4, 4, 1, 5, 8, 1, 1, 1, 1, 2, 4, 1, 1, 4,\n",
      "        8, 1, 8, 4, 2, 4, 2, 4, 4, 4, 4, 4, 1, 4, 5, 4, 6, 4, 8, 1, 8, 4, 0, 7,\n",
      "        8, 4, 4, 7, 6, 4, 4, 0, 2, 4, 8, 4, 8, 4, 3, 4, 8, 4, 4, 2, 8, 7, 1, 4,\n",
      "        1, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(max_probs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3, 2, 5, 2, 2, 4, 4, 2, 3, 0, 1, 5, 0, 6, 9, 0, 1, 8, 2, 2, 1, 9,\n",
       "        4, 1, 9, 4, 4, 3, 0, 4, 4, 0, 1, 8, 9, 3, 8, 7, 1, 7, 7, 1, 0, 3, 7, 2,\n",
       "        6, 1, 8, 4, 7, 4, 7, 7, 6, 6, 8, 1, 9, 6, 8, 2, 8, 8, 7, 9, 7, 2, 8, 7,\n",
       "        0, 3, 5, 4, 1, 3, 2, 5, 3, 4, 7, 5, 7, 0, 6, 2, 9, 6, 3, 4, 3, 5, 3, 6,\n",
       "        3, 4, 9, 9])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(l1,l2):\n",
    "    \n",
    "    return torch.sum(l1==l2).item()/len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3307, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(outputs,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,loss_func, xb,yb, opt= None,metric = None):\n",
    "    \n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    \n",
    "    if opt is not None:\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    \n",
    "    if metric is not None:\n",
    "        \n",
    "        metric_result = metric(preds,yb)\n",
    "        \n",
    "        \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, loss_fn, valid_dl, metric = None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        results = [loss_batch(model, loss_fn,xb, yb, metric = metric) for xb,yb in valid_dl]\n",
    "        \n",
    "        \n",
    "        losses, nums, metrics = zip(*results)\n",
    "        \n",
    "        \n",
    "        total = np.sum(nums)\n",
    "        \n",
    "        avg_loss = np.sum(np.multiply(losses,nums))/ total\n",
    "        \n",
    "        avg_metric = None\n",
    "        \n",
    "        if metric is not None:\n",
    "            \n",
    "            avg_metric = np.sum(np.multiply(metrics, nums ))/ total\n",
    "            \n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \n",
    "    _,preds = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return torch.sum(preds==labels).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3508, Accuracy : 0.1168\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, loss_fn,val_loader,metric= accuracy)\n",
    "\n",
    "print('Loss: {:.4f}, Accuracy : {:.4f}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model,loss_fn,opt,train_dl,valid_dl,metric = None):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            loss,_,_ = loss_batch(model,loss_fn,xb,yb,opt)\n",
    "            \n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_, total, val_metric = result\n",
    "        \n",
    "        if metric is None:\n",
    "            \n",
    "            print('Epoch [{}/{}],Loss:{:.4f}'.format(epoch+1,epochs,val_loss))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('Epoch [{}/{}],Loss:{:.4f},{}: {:.4f}'.format(epoch+1,epochs,val_loss,metric.__name__,val_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinstModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Loss:2.3508,accuracy: 0.6536\n",
      "Epoch [2/5],Loss:2.3508,accuracy: 0.7501\n",
      "Epoch [3/5],Loss:2.3508,accuracy: 0.7842\n",
      "Epoch [4/5],Loss:2.3508,accuracy: 0.7995\n",
      "Epoch [5/5],Loss:2.3508,accuracy: 0.8117\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,F.cross_entropy,optimizer,train_loader, val_loader,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Loss:2.3508,accuracy: 0.8193\n",
      "Epoch [2/5],Loss:2.3508,accuracy: 0.8259\n",
      "Epoch [3/5],Loss:2.3508,accuracy: 0.8299\n",
      "Epoch [4/5],Loss:2.3508,accuracy: 0.8340\n",
      "Epoch [5/5],Loss:2.3508,accuracy: 0.8381\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,F.cross_entropy,optimizer,train_loader, val_loader,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Loss:2.3508,accuracy: 0.8418\n",
      "Epoch [2/5],Loss:2.3508,accuracy: 0.8455\n",
      "Epoch [3/5],Loss:2.3508,accuracy: 0.8483\n",
      "Epoch [4/5],Loss:2.3508,accuracy: 0.8499\n",
      "Epoch [5/5],Loss:2.3508,accuracy: 0.8522\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,F.cross_entropy,optimizer,train_loader, val_loader,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ac541b6af0>]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [0.6536,.7501,.7842,.7842,.7995,.8117,.8193,.8259,.8299,.8340,.8381,.8418,.8455,.8483,.8499,.8522]\n",
    "plt.plot(accuracies,'-x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with inndividual Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/',train=False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape torch.Size([1, 28, 28])\n",
      "label 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "print('Shape', img.shape)\n",
    "print('label', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img,label):\n",
    "    xb = img.unsqueeze(0)\n",
    "    \n",
    "    yb = model(xb)\n",
    "    \n",
    "    _,preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 9 , Predicted : 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1000]\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "print('label :', label,', Predicted :',predict_image(img,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :0.6659, accuracy: 0.8606\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size = 200)\n",
    "\n",
    "test_loss,total, test_acc = evaluate(model,loss_fn,test_loader, metric = accuracy)\n",
    "print('Loss :{:.4f}, accuracy: {:.4f}'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'minst_logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-3.4863e-02, -2.9637e-03,  5.0653e-03,  ...,  3.1042e-02,\n",
       "                       -2.8909e-02, -1.0264e-02],\n",
       "                      [ 1.3737e-03, -2.0383e-03, -1.5564e-02,  ...,  2.6794e-02,\n",
       "                       -1.4217e-02, -2.5794e-02],\n",
       "                      [-2.4398e-02, -3.2709e-02,  1.7626e-03,  ...,  2.4153e-02,\n",
       "                        2.9140e-02,  7.8681e-03],\n",
       "                      ...,\n",
       "                      [ 3.2664e-03,  2.4436e-02, -9.4693e-03,  ..., -9.2267e-03,\n",
       "                       -1.3564e-02,  3.4407e-02],\n",
       "                      [ 1.0348e-02,  6.8460e-03,  2.7656e-02,  ...,  2.4367e-02,\n",
       "                       -2.4434e-02,  2.4465e-02],\n",
       "                      [-2.6956e-02,  1.4213e-02,  1.6719e-02,  ..., -1.3307e-02,\n",
       "                        3.3620e-02, -6.5606e-05]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0155,  0.0612, -0.0037,  0.0050, -0.0094,  0.0431, -0.0159,  0.0294,\n",
       "                      -0.0765,  0.0039]))])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-3.4863e-02, -2.9637e-03,  5.0653e-03,  ...,  3.1042e-02,\n",
       "                       -2.8909e-02, -1.0264e-02],\n",
       "                      [ 1.3737e-03, -2.0383e-03, -1.5564e-02,  ...,  2.6794e-02,\n",
       "                       -1.4217e-02, -2.5794e-02],\n",
       "                      [-2.4398e-02, -3.2709e-02,  1.7626e-03,  ...,  2.4153e-02,\n",
       "                        2.9140e-02,  7.8681e-03],\n",
       "                      ...,\n",
       "                      [ 3.2664e-03,  2.4436e-02, -9.4693e-03,  ..., -9.2267e-03,\n",
       "                       -1.3564e-02,  3.4407e-02],\n",
       "                      [ 1.0348e-02,  6.8460e-03,  2.7656e-02,  ...,  2.4367e-02,\n",
       "                       -2.4434e-02,  2.4465e-02],\n",
       "                      [-2.6956e-02,  1.4213e-02,  1.6719e-02,  ..., -1.3307e-02,\n",
       "                        3.3620e-02, -6.5606e-05]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0155,  0.0612, -0.0037,  0.0050, -0.0094,  0.0431, -0.0159,  0.0294,\n",
       "                      -0.0765,  0.0039]))])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MinstModel()\n",
    "model2.load_state_dict(torch.load('minst_logistic.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :0.6659, accuracy: 0.8606\n"
     ]
    }
   ],
   "source": [
    "test_loss, total, test_acc = evaluate(model2, loss_fn,test_loader, metric= accuracy)\n",
    "print('Loss :{:.4f}, accuracy: {:.4f}'.format(test_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
