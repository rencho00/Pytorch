{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=MNIST(root='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='data/',train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image,cmap='gray')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',train=True,transform= transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image_tensor, label = dataset[2]\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(image_tensor))\n",
    "print(torch.min(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(n,pct):\n",
    "    \n",
    "    n_val = int(n*pct)\n",
    "    indx = np.random.permutation(n)\n",
    "    \n",
    "    return indx[:n_val], indx[n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind, test_ind= split(len(dataset),0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_ind)\n",
    "train_loader = DataLoader(dataset,batch,sampler= train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(test_ind)\n",
    "val_loader = DataLoader(dataset,batch,sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "output = 10\n",
    "\n",
    "model = nn.Linear(input_size,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0159,  0.0302,  0.0117, -0.0240,  0.0270, -0.0138, -0.0015,  0.0038,\n",
      "        -0.0306, -0.0036], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-4.6663e-03, -8.4497e-05,  3.0873e-02,  ...,  1.6408e-03,\n",
       "           2.1387e-02,  2.4420e-02],\n",
       "         [-6.0723e-03,  1.2631e-02, -2.4341e-02,  ...,  9.4486e-03,\n",
       "           2.9194e-02, -1.8936e-02],\n",
       "         [-1.2051e-02,  2.6832e-02,  9.4269e-03,  ...,  3.1986e-02,\n",
       "           2.6326e-02,  2.2176e-02],\n",
       "         ...,\n",
       "         [ 9.6881e-03,  2.3360e-02, -5.3331e-04,  ..., -3.0007e-02,\n",
       "          -1.4982e-03, -2.8549e-02],\n",
       "         [-9.5794e-04, -3.3797e-03, -8.4076e-03,  ..., -2.6938e-02,\n",
       "           8.8728e-03,  3.4069e-02],\n",
       "         [-3.0463e-02, -1.1310e-02, -3.5026e-02,  ..., -1.8847e-02,\n",
       "          -1.3883e-03, -5.5568e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0159,  0.0302,  0.0117, -0.0240,  0.0270, -0.0138, -0.0015,  0.0038,\n",
       "         -0.0306, -0.0036], requires_grad=True)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinstModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.linear1=nn.Linear(input_size,hidden_size)\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        xb = xb.reshape(-1,input_size)\n",
    "        out = self.linear1(xb)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinstModel(input_size,hidden_size=32,out_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 2.317988395690918\n",
      "torch.Size([100, 10])\n",
      "tensor([[0.0814, 0.0879, 0.0957, 0.1273, 0.1007, 0.0849, 0.0833, 0.1143, 0.1198,\n",
      "         0.1049],\n",
      "        [0.0899, 0.0875, 0.0955, 0.1260, 0.1045, 0.0876, 0.0810, 0.1154, 0.1125,\n",
      "         0.1001]])\n"
     ]
    }
   ],
   "source": [
    "for images, label in train_loader:\n",
    "    outputs = model(images)\n",
    "    \n",
    "    loss = F.cross_entropy(outputs,label)\n",
    "    \n",
    "    print('LOSS',loss.item())\n",
    "    break\n",
    "    \n",
    "    \n",
    "print((outputs.shape))\n",
    "print(F.softmax(outputs[:2].data,dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        \n",
    "        return torch.device('cuda')\n",
    "    \n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        \n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images,label in train_loader:\n",
    "    \n",
    "    print(images.shape)\n",
    "    \n",
    "    images = to_device(images,device)\n",
    "    \n",
    "    print(images.device)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \n",
    "    def __init__(self,dl,device):\n",
    "        \n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "            \n",
    "        for b in self.dl:\n",
    "                \n",
    "            yield to_device(b,self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return (self.dl)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_loader,device)\n",
    "valid_dl = DeviceDataLoader(val_loader,device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "tensor([4, 4, 1, 0, 1, 7, 1, 6, 2, 1, 7, 6, 7, 7, 5, 4, 7, 7, 3, 1, 0, 2, 3, 8,\n",
      "        8, 8, 5, 8, 8, 5, 9, 8, 1, 5, 3, 6, 7, 1, 5, 5, 8, 3, 0, 4, 6, 0, 2, 0,\n",
      "        1, 8, 7, 5, 0, 1, 3, 5, 7, 0, 9, 7, 9, 6, 6, 1, 7, 6, 7, 2, 1, 7, 5, 2,\n",
      "        9, 4, 4, 9, 0, 3, 7, 0, 3, 9, 0, 7, 9, 3, 2, 2, 3, 6, 2, 3, 1, 6, 7, 4,\n",
      "        7, 6, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in valid_dl:\n",
    "    \n",
    "    print(xb.device)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,loss_func, xb,yb, opt= None,metric = None):\n",
    "    \n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    \n",
    "    if opt is not None:\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    \n",
    "    if metric is not None:\n",
    "        \n",
    "        metric_result = metric(preds,yb)\n",
    "        \n",
    "        \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, loss_fn, valid_dl, metric = None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        results = [loss_batch(model, loss_fn,xb, yb, metric = metric) for xb,yb in valid_dl]\n",
    "        \n",
    "        \n",
    "        losses, nums, metrics = zip(*results)\n",
    "        \n",
    "        \n",
    "        total = np.sum(nums)\n",
    "        \n",
    "        avg_loss = np.sum(np.multiply(losses,nums))/ total\n",
    "        \n",
    "        avg_metric = None\n",
    "        \n",
    "        if metric is not None:\n",
    "            \n",
    "            avg_metric = np.sum(np.multiply(metrics, nums ))/ total\n",
    "            \n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr,model,loss_fn,train_dl,valid_dl,metric = None,opt_fn = None):\n",
    "    \n",
    "    \n",
    "    losses,metrics = [],[]\n",
    "    \n",
    "    if opt_fn is None:\n",
    "        \n",
    "        opt_fn = torch.optim.SGD\n",
    "    \n",
    "    opt = opt_fn(model.parameters(),lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            loss_batch(model,loss_fn,xb,yb,opt)\n",
    "            \n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_, total, val_metric = result\n",
    "        \n",
    "        losses.append(val_loss)\n",
    "        \n",
    "        metrics.append(val_metric)\n",
    "        \n",
    "        \n",
    "        if metric is None:\n",
    "            \n",
    "            print('Epoch [{}/{}],Loss:{:.4f}'.format(epoch+1,epochs,val_loss))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('Epoch [{}/{}],Loss:{:.4f},{}: {:.4f}'.format(epoch+1,epochs,val_loss,metric.__name__,val_metric))\n",
    "            \n",
    "    return losses , metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \n",
    "    _,preds = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return torch.sum(preds==labels).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinstModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MinstModel(input_size,hidden_size = 32, out_size = 10)\n",
    "\n",
    "to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3185, Accuracy : 0.0664\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, loss_fn,val_loader,metric= accuracy)\n",
    "\n",
    "print('Loss: {:.4f}, Accuracy : {:.4f}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Loss:2.3185,accuracy: 0.3255\n",
      "Epoch [2/5],Loss:2.3185,accuracy: 0.5396\n",
      "Epoch [3/5],Loss:2.3185,accuracy: 0.7069\n",
      "Epoch [4/5],Loss:2.3185,accuracy: 0.7783\n",
      "Epoch [5/5],Loss:2.3185,accuracy: 0.8068\n"
     ]
    }
   ],
   "source": [
    "losses1,metrics1 =  fit(5,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Loss:2.3185,accuracy: 0.8223\n",
      "Epoch [2/5],Loss:2.3185,accuracy: 0.8358\n",
      "Epoch [3/5],Loss:2.3185,accuracy: 0.8453\n",
      "Epoch [4/5],Loss:2.3185,accuracy: 0.8524\n",
      "Epoch [5/5],Loss:2.3185,accuracy: 0.8591\n"
     ]
    }
   ],
   "source": [
    "losses1,metrics1 =  fit(5,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
